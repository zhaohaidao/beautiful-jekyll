---
layout: post
title: kafka-choose-the-number-of-partitions（译）
---
# 来源
https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster/
# More Partitions Lead to Higher Throughput
## 吞吐量和partition数量成正比
+ 针对producer和broker，写入到不同分区的操作，完全可以并行
+ 针对consumer，kafka限制每个partition同时只能被1个consumer消费，因此，消费并行度受分区数目的限制
## 根据吞吐量计算分区数
+ PartitionNumber=max(t/p, t/c)
    + t: 目标吞吐量
    + p: 单partition的生产吞吐量
    + c: 单partition的消费吞吐量
## 单partition生产吞吐量的影响因素
+ batch-size
+ compression-codec
+ request-required-acks
+ replication-factor
+ etc.
## 单partition消费吞吐量的影响因素
+ 消费吞吐量取决于消费逻辑处理每个消息的速度
+ 需要按需测量
## 生产带key消息时需小心
+ 带key消息保证相同key的消息被分配到同一个分区
+ 如果分区数变更，以上保证则不再成立
+ 为了避免以上问题，最初的分区数可以设置的比实际需要的数大一些
    + 起初，可以根据当前吞吐创建小型集群
    + 随着流量增长，可以增加更多的brokers，并将一部分分区转移到新brokers上
    + 这样就可以跟上吞吐量的增长，而不打破带key消息的语义
# More Partitions Requires More Open File Handles
+ kafka为每个分区的当前日志段（log segment）都会分配2个fd：索引文件和实际数据文件
+ 因此分区数越多，占用的fd就越多
+ 这暂时不是大问题，kafka支持每个broker持有超过30K的fd正常运行
# More Partitions May Increase Unavailability
## Kafka通过多副本实现更高的可用性
+ broker异常时，kakfa读写zk实现切主
    + controller向zk写入最新的主的元信息
    + broker监听主的元信息变更事件
+ 现有版本，controller对zk的操作是串行的，短时间内大量元信息变更可能会延迟，导致broker无法发现新主
## Broker宕机对kafka的影响
+ 优雅关闭
    + 在关闭前， controller会将leaders从关闭的broker中移出，一次1个，而切主花费只需几毫秒
    + 因此，站在客户端的角度，不可用窗口很短
+ 异常关闭（kill -9）
    + 客户端观测到的不可用性和分区数成正比，假如1个broker上有1000个主，切1个主耗费5ms，那么切完所有主需要花费5秒（对zk的操作是串行的）
    + 这就意味着对于某些分区，不可用窗口可能长达5+秒（包含故障检测时间）
    + 如果宕机的broker同时也是controller，情况会更糟：controller转移至新的broker后，才会开始分区的切主操作
        + controller转移到新的机器后，需要进行初始化工作，将broker的原信息读取到内存中，这部分花费的时间和分区规模成长比
        + 因此需要隔离controller和读写数据的broker
    + 因此，如果关注可用性，建议限制单个broker的分区数不超过4K，集群总分区数不超过10K
# More Partitions May Increase End-to-end Latency
## 端到端延迟
+ 生产者发布消息到消费者消费消息之间的时间间隔
+ 消息只有被提交后（committed）才能被消费到
## 提交消息耗时是端到端延迟的重要组成部分
+ kafka broker默认使用单线程从另一个broker复制消息
    + 复制线程数受num.replica.fetchers控制，可以通过调整该配置优化提交延迟
    + 总体来说，分区数越多，复制耗时会越长（线程数是否是瓶颈？）
+ 实验表明，将1000个分区从一个broker复制到另一个broker会增加20ms的延迟，这意味着端到端延迟至少是20ms，对于某些实时应用，延迟太高了
+ 根据经验，单broker的分区数限制在100*b*r
    + b: broker数量
    + r: replication factor
# More Partitions May Require More Memory In the Client
## Producer支持设置缓冲的内存量上限
+ 0.8.2+的版本支持
+ Producer会分别为每个分区缓冲消息
## 分区数增多会导致内存总量超过设置上限
+ 生产者要么丢弃消息，要么等待,这都不是理想的处理方式
    + 等待时间受max-block-ms控制
+ 根据经验，应该为每个分区保留至少几十KB的空间，并在分区数显著增加的情况下，调整内存总量
    + max-memory-bytes
    + max-partition-memory-bytes
+ 对于消费者而言，问题是类似的，分区数越多，消费者需要的内存也就越多
# Summary
通常来说，分区数越多，吞吐越高。但是必须意识到，过多的分区数会对可用性和延迟产生潜在的影响。